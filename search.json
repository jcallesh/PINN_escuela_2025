[
  {
    "objectID": "PINN_notebook.html",
    "href": "PINN_notebook.html",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "",
    "text": "Juan Calles - juan.calles@uv.cl\n\n\nEscuela de F√≠sica Te√≥rica de Valpara√≠so\n\n\n3 - 4 - 5 de Diciembre de 2025\n\n\nFacultad de Ciencias y Edificio CIAE\n\n\nUniversidad de Valpara√≠so"
  },
  {
    "objectID": "PINN_notebook.html#punto-de-partida-necesitamos-datos",
    "href": "PINN_notebook.html#punto-de-partida-necesitamos-datos",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "1.1 üî¢ Punto de partida: ¬°Necesitamos datos!",
    "text": "1.1 üî¢ Punto de partida: ¬°Necesitamos datos!\nPara comenzar cualquier proceso de modelado o an√°lisis, lo primero que necesitamos son datos.\nT√≠picamente, estos se presentan como:\n\nEntradas (inputs): \\(x_{1:N}=(x_1,x_2,...,x_N)\\) - donde cada \\(x_i\\) representa una observaci√≥n o conjunto de caracter√≠sticas.\nSalidas (outputs): \\(y_{1:N}=(y_1,y_2,...,y_N)\\) - que corresponden a las respuestas, etiquetas o valores asociados a cada entrada.\n\nEste par \\(\\mathcal{D}= \\{x_i,\\, y_i\\}_{i=1}^{N}\\) forma lo que llamamos una muestra (sample) de entrenamiento, y el conjunto completo de pares nos permite aprender patrones, ajustar modelos, o validar hip√≥tesis que expliquen el proceso que generaron los outputs!.\nüéØ Objetivo: simular una se√±al tipo seno con ruido gaussiano\nAntes de aplicar cualquier modelo, vamos a generar nuestros propios datos. Estos datos ser√°n sint√©ticos, es decir, creados artificialmente en lugar de recolectados del mundo real.\n¬øPor qu√© usar datos sint√©ticos?\n\nControl total: Podemos definir exactamente la estructura, el ruido (noise) y las propiedades estad√≠sticas.\nValidaci√≥n de modelos: Son ideales para probar si un modelo puede recuperar patrones conocidos.\nDiagn√≥stico pedag√≥gico: Permiten ilustrar conceptos sin depender de datos externos o complicaciones reales.\n\nVamos a generar \\(N\\) puntos de entrada \\(x_i\\) distribuidos uniformemente en un intervalo (por ejemplo, \\([0, 2\\pi]\\)), y para cada uno calcularemos una salida \\(y_i\\) como:\n\\[y_i = \\sin(x_i) + \\epsilon_i\\]\ndonde \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\) es ruido Gaussiano/Normal con media cero y varianza \\(\\sigma^2\\).\nEsto nos da un conjunto de datos \\(\\{x_i,\\, y_i\\}\\) que emula una se√±al peri√≥dica con perturbaciones aleatorias - un escenario com√∫n en f√≠sica, astronom√≠a, y procesamiento de se√±ales.\n\n# Completar la siguiente funci√≥n para que genere un conjunto de datos sint√©ticos que emule una distribuci√≥n seno + ruido gaussiano\ndef generar_datos(num_puntos, desviacion_ruido=0.1):\n    # Generar valores aleatorios para x\n    valores_x = np.sort(np.random.uniform(0, 2 * np.pi, num_puntos))\n    # Generar los correspondientes valores de y = sen(x) + N(0, desviaci√≥n)\n    valores_y = np.sin(valores_x) + np.random.normal(0, desviacion_ruido, num_puntos)\n    return valores_x, valores_y\n\nnum_puntos = 1000\n\n# Agregue un par√°metro a la funci√≥n que module el nivel de ruido de los datos atraves de la desviaci√≥n estandard sigma\nx_train, y_train= generar_datos(num_puntos, desviacion_ruido=0.1)\n\nAntes de entrenar cualquier modelo, lo m√°s importante es visualizar y entender c√≥mo lucen nuestros datos. Esto nos permite detectar patrones, outliers, ruido o posibles errores de generaci√≥n.\n\nüí° Nota: Cuando los datos son ‚Äúsint√©ticos‚Äù tenemos la ventaja de conocer la distribuci√≥n exacta que deber√≠an seguir.\n\n\n# Gr√°fico simple de los datos vs. la funci√≥n real\nplt.figure(figsize=(8, 5))\n\nplt.scatter(x_train, y_train, label='Datos generados con ruido', alpha=0.5)\nplt.plot(x_train, np.sin(x_train), color='k', linestyle='--',label='Curva seno verdadera')\n\nplt.legend()\nplt.title('Datos generados de onda seno con ruido')\nplt.xlabel('Valores de X')\nplt.ylabel('Valores de Y')\nplt.show()"
  },
  {
    "objectID": "PINN_notebook.html#red-neuronal",
    "href": "PINN_notebook.html#red-neuronal",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "1.2 üï∏Ô∏è Red Neuronal",
    "text": "1.2 üï∏Ô∏è Red Neuronal\nNuestro objetivo ahora es construir una red neuronal capaz de aprender a ajustar los datos sint√©ticos generados previamente. Para ello, implementaremos un Perceptr√≥n Multicapa (MLP, Multilayer Perceptron), que es la forma m√°s b√°sica ‚Äîy a la vez m√°s vers√°til‚Äî de red neuronal.\n\nUn MLP est√° formado por varias capas lineales (fully connected layers), donde cada neurona se conecta con todas las de la capa anterior.\nEntre estas capas se insertan funciones de activaci√≥n que introducen no linealidad, permitiendo que la red aprenda relaciones complejas entre entrada y salida.\n\nEn t√©rminos generales, nuestro modelo puede entenderse como una funci√≥n, \\(\\hat{y}\\), parametrizada por los pesos(weights) y sesgos(biases) de la red \\((w_{ij}, b_i)\\), que agrupamos bajo el s√≠mbolo \\(\\theta\\). As√≠, la red \\(\\hat{y}_\\theta\\) representa una funci√≥n que depende de estos par√°metros, toma como entrada los valores \\(x_i\\), y produce como salida las predicciones correspondientes.\nArquitectura propuesta\n\nCapa 1: Lineal, transforma las entradas en una representaci√≥n de dimensi√≥n intermedia.\nFunci√≥n de activaci√≥n: puede ser ReLU (m√°s simple y r√°pida) o Tanh (m√°s suave y √∫til para funciones continuas).\nCapa 2: Lineal, genera la salida final del modelo.\n\nAyuda:\n    nn.Linear(input,output)\n    nn.Conv2d(input,output)\n    nn.functional.tanh\n    nn.function.relu\n    nn.function.softmax\n\nclass MLP(nn.Module):\n    def __init__(self):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(1, 10)          # Fully connected layer: 1 input feature, 10 hidden units\n        self.activation = nn.functional.tanh # Funci√≥n de activaci√≥n\n        self.fc2 = nn.Linear(10, 1)          # Fully connected layer: 10 hidden units, 1 output\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.activation(x)\n        x = self.fc2(x)\n        return x\n\nüß† ¬øC√≥mo entrenamos nuestro modelo?\n‚ÄúAprender‚Äù significa ajustar los par√°metros internos de la red ‚Äîdenotados por \\(\\theta\\)‚Äî para que las predicciones \\(\\hat{y}_i\\) se acerquen lo m√°s posible a los valores reales \\(y_i\\). Este proceso se basa en dos componentes esenciales:\n\nMinimizaci√≥n de una funci√≥n de costo (Loss function):\nPara medir qu√© tan bien est√° funcionando el modelo, usamos una funci√≥n de costo que cuantifica el error entre las predicciones y los datos reales. Una de las m√°s comunes es el Error Cuadr√°tico Medio (MSE):\n\\[\n\\mathcal{L} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i - \\hat{y}_i \\right)^2\n\\] donde \\(y_i\\) es el valor real y \\(\\hat{y}_i\\) es la predicci√≥n del modelo para la entrada \\(x_i\\). &gt; Notenemos que necesitamos 3 argumentos \\(\\{x_i,\\hat{y}(x_i),y(x_i)\\}\\) para evaluar esta funci√≥n!\nActualizaci√≥n por descenso del gradiente:\nPara encontrar los valores √≥ptimos de los par√°metros del modelo (\\(\\theta\\)) que minimizan la funci√≥n de costo (\\(\\mathcal{L}\\)), se utiliza el m√©todo de descenso del gradient (gradient descent). La idea central es mover los par√°metros en la direcci√≥n opuesta al gradiente de la p√©rdida ‚Äîes decir, en la direcci√≥n que m√°s reduce el error:\n\\[\n\\theta_{t+1} = \\theta_t - \\eta , \\nabla_\\theta \\mathcal{L}\n\\]\ndonde:\n\n\\(\\eta\\) es la tasa de aprendizaje (learning rate), que controla qu√© tan grande es cada paso de actualizaci√≥n.\n\\(\\nabla_\\theta \\mathcal{L}\\) es el gradiente de la p√©rdida respecto a los par√°metros del modelo.\n\nEste gradiente indica la direcci√≥n de mayor aumento de la p√©rdida; por eso se resta en la actualizaci√≥n.\nEn la pr√°ctica, los gradientes se calculan mediante diferenciaci√≥n autom√°tica (automatic differentiation) en librer√≠as como PyTorch, TensorFlow, JAX o SciML.\n\n\nExisten distintos optimizadores que implementan variantes del descenso del gradiente:\n\nSGD (Stochastic Gradient Descent): usa un subconjunto aleatorio de datos en cada iteraci√≥n.\nRMSProp: ajusta din√°micamente el tama√±o de paso para cada par√°metro seg√∫n la magnitud reciente de sus gradientes.\nAdam: combina las ideas de momentum y escalamiento adaptativo de tasa de aprendizaje, siendo hoy el m√°s popular por su estabilidad y rapidez de convergencia.\n\n\nEste ciclo ‚Äîcalcular la p√©rdida ‚Üí obtener los gradientes ‚Üí actualizar par√°metros‚Äî se repite muchas veces hasta que:\n\nla p√©rdida sea lo suficientemente baja,\nel modelo converja, o\nse alcance el n√∫mero m√°ximo de iteraciones.\n\n\nüí° En t√©rminos simples: el modelo aprende repitiendo peque√±os pasos en la direcci√≥n correcta, hasta ‚Äúentender‚Äù los datos.\n\n\ndef train_epoch(inputs, model, targets, optimizer, criterion):\n    model.train()\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\ndef evaluate(model, x_test):\n    model.eval()\n    with torch.no_grad():\n        y_pred = model(x_test.view(-1, 1)).cpu().numpy()\n    return y_pred\n\n\nmodelo       = MLP()\ncriterio     = nn.MSELoss()\noptimizador  = optim.Adam(modelo.parameters(), lr=1e-2)\n\n#numero de parametros de la red\nnumero_parametros = sum(p.numel() for p in modelo.parameters())\nprint(f\"Number of parameters: {numero_parametros}\")\n\nNumber of parameters: 31\n\n\n\nnum_epocas = 1000\nfor epoca in range(num_epocas):\n    # Convertimos los datos a Tensores de pytorch\n    x_i  = torch.tensor(x_train, dtype=torch.float32, requires_grad=True).view(-1, 1) #inputs\n    y = torch.tensor(y_train, dtype=torch.float32).view(-1, 1) #targets\n\n    # Entrenamos\n    loss = train_epoch(x_i, modelo, y, optimizador, criterio)\n\n    if (epoca+1) % 100 == 0:\n        print(f'Epoch [{epoca+1}/{num_epocas}], Loss: {loss:.4f}')\n\nEpoch [100/1000], Loss: 0.0941\nEpoch [200/1000], Loss: 0.0522\nEpoch [300/1000], Loss: 0.0293\nEpoch [400/1000], Loss: 0.0164\nEpoch [500/1000], Loss: 0.0117\nEpoch [600/1000], Loss: 0.0107\nEpoch [700/1000], Loss: 0.0105\nEpoch [800/1000], Loss: 0.0104\nEpoch [900/1000], Loss: 0.0104\nEpoch [1000/1000], Loss: 0.0103\n\n\nYa tenemos nuestro modelo entrenado! Pero‚Ä¶ ¬ørealmente aprendi√≥ algo √∫til?\nPara responderlo, haremos una inspecci√≥n visual de las predicciones \\(\\hat{y}_i\\) generadas por la red.\nüìà Una visualizaci√≥n t√≠pica incluye:\n\nDatos de entrenamiento: los puntos originales \\((x_i, y_i)\\), que representan nuestras observaciones.\nPredicci√≥n del modelo: la funci√≥n \\(\\hat{y}(x_{\\text{new}})\\) evaluada en un conjunto de puntos nuevos y m√°s densos, para ver la forma continua que aprendi√≥.\nSoluci√≥n real (si la conocemos): \\(y(x_{\\text{new}})\\) evaluada en los mismos puntos del paso anterior, para comparar con la salida de la red.\n\nüîç ¬øQu√© podemos observar de este gr√°fico?\n\nSi el modelo captura correctamente la forma general de la funci√≥n (por ejemplo, una senoide).\nSi existen zonas sistem√°ticamente mal ajustadas, lo que indicar√≠a un sesgo estructural o falta de capacidad del modelo.\nSi la predicci√≥n es suavizada, ruidosa o err√°tica, lo cual da pistas sobre el balance entre complejidad y regularizaci√≥n.\n\n\nx_test = torch.linspace(0, 2*np.pi, 100) # x_nuevos\ny_pred = evaluate(modelo, x_test) # Nuestro modelo evaluado en los nuevos puntos x\n\nx_test = x_test.cpu().numpy()\ny_test = np.sin(x_test) # Funcion verdadera evaluada en los nuevos puntos x_new\n\nplt.figure(figsize=(10, 6))\nplt.scatter(x_train, y_train, label='Datos de entrenamiento',alpha=0.5)\nplt.plot(x_test, y_pred, label='Curva aprendida', color='red')\nplt.plot(x_test, y_test, color='k', linestyle='--',label='Curva seno verdadera')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nExtra para pensar:\n- ¬øQu√© sucede si incrementamos \\(\\sigma\\) en nuestro generador de datos?\n- ¬øC√≥mo se comporta nuestro modelo para valores m√°s altos o m√°s bajos de \\(\\sigma\\)?\n\nOtro tipo de visualizaci√≥n implica gr√°ficar la curva de la funci√≥n de coste versus el n√∫mero de √©pocas.\nPara ello, modifiqu√© la rutina de entrenamiento para que guarde el valor de la p√©rdida en cada √©poca y luego grafique loss vs epochs.\n\n# num_epochs = 1000\n# for epoch in range(num_epochs):\n#     # Convertimos los datos a Tensores de pytorch\n#     inputs  = torch.tensor(x_train, dtype=torch.float32, requires_grad=True).view(-1, 1) #esto cambien nuestros datos a un tensor de dim (Npuntos,1)\n#     targets = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n\n#     # Entrenamos\n#     loss = train_epoch(inputs, modelo,targets, optimizador, function_coste)\n\n#     if (epoch+1) % 100 == 0:\n#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}')\n\n\n# plt.plot(lista_epocas, lista_costos, lw=2, label = 'Loss entrenamiento')\n# plt.xlabel('Epocas')\n# plt.ylabel('MSE_loss')\n# plt.legend()\n# plt.show()\n\nüîç ¬øQu√© podemos observar de este gr√°fico? - Verificar si el modelo est√° convergiendo. - Detectar oscilaciones o problemas con la tasa de aprendizaje (learning rate, \\(\\eta\\)). - Identificar ‚Äúoverfitting‚Äù si la p√©rdida se estabiliza pero el modelo no mejora"
  },
  {
    "objectID": "PINN_notebook.html#autograd",
    "href": "PINN_notebook.html#autograd",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "1.3 ‚öôÔ∏è Autograd",
    "text": "1.3 ‚öôÔ∏è Autograd\nAhora que ya tenemos nuestro modelo entrenado, podemos hacer algo muy √∫til: calcular derivadas de la salida de la red con respecto a sus entradas.\nEsto es posible gracias a una herramienta fundamental en PyTorch llamada autograd. En otras palabras, podemos obtener: \\[\\dfrac{d}{dx}\\hat{y}(x)\\] de forma autom√°tica, sin necesidad de derivar la red ‚Äúa mano‚Äù.\n\n# Crear un conjunto de inputs con gradientes habilitados\nx_test = torch.linspace(0, 2 * np.pi, 100).view(-1, 1).requires_grad_(True)\n\n# Obtener las predicciones del modelo\npredicciones = modelo(x_test)\n\n# Calcular la derivada de las predicciones respecto a los inputs\ndy_dx = torch.autograd.grad(\n    outputs=predicciones,\n    inputs=x_test,\n    grad_outputs=torch.ones_like(predicciones),\n    create_graph=True,\n    retain_graph=True\n)[0]\n\nVeamos que tan buena es nuestra derivada\n\nplt.figure(figsize=(10, 6))\n\n# Asegurarse de que x y dy_dx est√©n en formato NumPy para usar en matplotlib.plt\nx = x_test.detach().cpu().numpy()\ndy_dx_np = dy_dx.detach().cpu().numpy()\n\n# Graficar derivada real y derivada aprendida\nplt.plot(x, np.cos(x), label='Derivada real (cos(x))', linestyle='--', color='blue', alpha=0.7)\nplt.plot(x, dy_dx_np, label='Derivada autograd del modelo', color='red')\n\n# Est√©tica del gr√°fico\nplt.title('Comparaci√≥n entre derivada real y derivada aprendida')\nplt.xlabel('x')\nplt.ylabel('dy/dx')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nEjercicios extra:\n\nExperimenta con el modelo para explorar c√≥mo responde a distintos escenarios:\n\nPara una funci√≥n rapidamente oscilante \\[\\sin(\\frac{2n\\pi x}{L})\\] con \\(L=1\\) y diferentes valores de \\(n=5,20,50\\).\nQu√© sucede con el modelo?\nQu√© rol juega la capacidad del modelo (n√∫mero de neuronas, activaciones, n√∫mero de capas)\nC√≥mo afecta el tama√±o del dataset y la densidad de puntos?\n\n¬øC√≥mo se podr√≠a calcular la segunda derivada de esta funci√≥n utilizando autograd en PyTorch?\n\n\\[ \\dfrac{d}{dx} \\left(\\dfrac{d}{dx}\\hat{y}(x)\\right)\\]\n\n\nd2y_dx2 = torch.autograd.grad(\n    outputs=dy_dx,\n    inputs=x_test,\n    grad_outputs=torch.ones_like(dy_dx),\n    create_graph=True,\n    retain_graph=True\n)[0]\n\n\nplt.figure(figsize=(10, 6))\n\n# Asegurarse de que x y dy_dx est√©n en formato NumPy\n\nd2y_dx2_np = d2y_dx2.detach().cpu().numpy()\n\n# Graficar derivada real y derivada aprendida\nplt.plot(x, -np.sin(x), label='Segunda Derivada (-sin(x))', linestyle='--', color='blue', alpha=0.7)\nplt.plot(x, d2y_dx2_np, label='Segunda Derivada autograd del modelo', color='red')\n\n# Est√©tica del gr√°fico\nplt.title('Comparaci√≥n entre derivada real y autograd')\nplt.xlabel('x')\nplt.ylabel('d2y/dx2')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "",
    "text": "Juan Calles - juan.calles@uv.cl\n\n\nEscuela de F√≠sica Te√≥rica de Valpara√≠so\n\n\n3 - 4 - 5 de Diciembre de 2025\n\n\nFacultad de Ciencias y Edificio CIAE\n\n\nUniversidad de Valpara√≠so"
  },
  {
    "objectID": "intro.html#referencias",
    "href": "intro.html#referencias",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "1.1 Referencias",
    "text": "1.1 Referencias\n\nPhysics Informed Machine Learning: High Level Overview of AI and ML in Science and Engineering - Steve Brunton\nCAMLab-youtube\nCAMLab-DLSCTutorials\nAN EXPERT‚ÄôS GUIDE TO TRAINING PHYSICS-INFORMED NEURAL NETWORKS\nPINNpapers\n\nEjemplos en Gravitacti√≥n y Cosmolog√≠a:\n\nCosmology-informed Neural Networks to infer dark energy equation-of-state\nEINSTEIN FIELDS: A NEURAL PERSPECTIVE TO COMPUTATIONAL GENERAL RELATIVITY\nAdvancing Cosmological Simulations of Fuzzy Dark Matter with PINN\nAInstein: Numerical Einstein Metrics via Machine Learning\nQuasinormal Modes in Modified Gravity using PINN\nPINNferring the Hubble Function with Uncertainties\nSolving the Regge-Wheeler and Teukolsky equations: supervised versus unsupervised PINN\nGradient-Annihilated PINNs for Solving Riemann Problems: Application to Relativistic Hydrodynamics\nSolving the Teukolsky equation with PINN"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PINNs - Escuela de F√≠sica Te√≥rica de Valpara√≠so 2025",
    "section": "",
    "text": "Este sitio contiene el material de la clase sobre PINNs presentada en la Escuela de F√≠sica Te√≥rica de Valpara√≠so 2025.\n\n\n\nIntroducci√≥n a PINNs\nHands-on session\n\n\n\n\nAplicar m√©todos num√©ricos modernos de aprendizaje autom√°tico para resolver problemas f√≠sicos modelados mediante ecuaciones diferenciales parciales (EDPs).\n\n\n\nPuedes navegar por las secciones desde la barra superior o usando los enlaces anteriores. Cada notebook est√° dise√±ado para ser autoexplicativo y ejecutable."
  },
  {
    "objectID": "index.html#contenido",
    "href": "index.html#contenido",
    "title": "PINNs - Escuela de F√≠sica Te√≥rica de Valpara√≠so 2025",
    "section": "",
    "text": "Introducci√≥n a PINNs\nHands-on session"
  },
  {
    "objectID": "index.html#objetivo",
    "href": "index.html#objetivo",
    "title": "PINNs - Escuela de F√≠sica Te√≥rica de Valpara√≠so 2025",
    "section": "",
    "text": "Aplicar m√©todos num√©ricos modernos de aprendizaje autom√°tico para resolver problemas f√≠sicos modelados mediante ecuaciones diferenciales parciales (EDPs)."
  },
  {
    "objectID": "index.html#c√≥mo-usar-este-sitio",
    "href": "index.html#c√≥mo-usar-este-sitio",
    "title": "PINNs - Escuela de F√≠sica Te√≥rica de Valpara√≠so 2025",
    "section": "",
    "text": "Puedes navegar por las secciones desde la barra superior o usando los enlaces anteriores. Cada notebook est√° dise√±ado para ser autoexplicativo y ejecutable."
  },
  {
    "objectID": "PINN_escuela_2025.html",
    "href": "PINN_escuela_2025.html",
    "title": "PINN_escuela_2025",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "PINN_escuela_2025.html#quarto",
    "href": "PINN_escuela_2025.html#quarto",
    "title": "PINN_escuela_2025",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  }
]