[
  {
    "objectID": "PINN_notebook.html",
    "href": "PINN_notebook.html",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "",
    "text": "Juan Calles - juan.calles@uv.cl\n\n\nEscuela de F√≠sica Te√≥rica de Valpara√≠so\n\n\n3 - 4 - 5 de Diciembre de 2025\n\n\nFacultad de Ciencias y Edificio CIAE\n\n\nUniversidad de Valpara√≠so"
  },
  {
    "objectID": "PINN_notebook.html#punto-de-partida-necesitamos-datos",
    "href": "PINN_notebook.html#punto-de-partida-necesitamos-datos",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "1.1 üî¢ Punto de partida: ¬°Necesitamos datos!",
    "text": "1.1 üî¢ Punto de partida: ¬°Necesitamos datos!\nPara comenzar cualquier proceso de modelado o an√°lisis, lo primero que necesitamos son datos!\nT√≠picamente, estos se presentan como:\n\nEntradas (inputs): \\(x_{1:N}=(x_1,x_2,...,x_N)\\) - donde cada \\(x_i\\) representa una observaci√≥n o conjunto de caracter√≠sticas.\nSalidas (outputs): \\(y_{1:N}=(y_1,y_2,...,y_N)\\) - que corresponden a las respuestas, etiquetas o valores asociados a cada entrada.\n\nEste par \\(\\mathcal{D} = \\{x_i,\\, y_i\\}_{i=1}^{N}\\) forma lo que llamamos una muestra (sample) de entrenamiento, y el conjunto completo de pares nos permite aprender patrones estad√≠sticos, ajustar modelos, o validar hip√≥tesis que expliquen el proceso que generaron los outputs!.\nüéØ Objetivo: simular una se√±al tipo seno con ruido gaussiano\nAntes de aplicar cualquier modelo, vamos a generar nuestros propios datos. Estos datos ser√°n sint√©ticos, es decir, creados artificialmente en lugar de recolectados del mundo real.\n¬øPor qu√© usar datos sint√©ticos?\n\nControl total: Podemos definir exactamente la estructura, el ruido (noise) y las propiedades estad√≠sticas.\nValidaci√≥n de modelos: Son ideales para probar si un modelo puede recuperar patrones conocidos.\nDiagn√≥stico pedag√≥gico: Permiten ilustrar conceptos sin depender de datos externos o complicaciones reales.\n\nVamos a generar \\(N\\) puntos de entrada \\(x_i\\) distribuidos uniformemente en un intervalo (por ejemplo, \\([0, 2\\pi]\\)), y para cada uno calcularemos una salida \\(y_i\\) como:\n\\[y_i = \\sin(x_i) + \\epsilon_i\\]\ndonde \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\) es ruido Gaussiano/Normal con media cero y varianza \\(\\sigma^2\\).\nEsto nos da un conjunto de datos \\(\\{x_i,\\, y_i\\}\\) que emula una se√±al peri√≥dica con perturbaciones aleatorias - un escenario com√∫n en f√≠sica, astronom√≠a, y procesamiento de se√±ales.\n\n# Completar la siguiente funci√≥n para que genere un conjunto de datos sint√©ticos que emule una distribuci√≥n seno + ruido gaussiano\ndef generar_datos(num_puntos, desviacion_ruido=0.1):\n    # Generar valores aleatorios para x\n    valores_x = np.sort(np.random.uniform(0, 2 * np.pi, num_puntos))\n    # Generar los correspondientes valores de y = sen(x) + N(0, desviaci√≥n)\n    valores_y = np.sin(valores_x) + np.random.normal(0, desviacion_ruido, num_puntos)\n    return valores_x, valores_y\n\nnum_puntos = 1000\n\n# Agregue un par√°metro a la funci√≥n que module el nivel de ruido de los datos atraves de la desviaci√≥n estandard sigma\nx_train, y_train= generar_datos(num_puntos, desviacion_ruido=0.1)\n\nAntes de entrenar cualquier modelo, lo m√°s importante es visualizar y entender c√≥mo lucen nuestros datos. Esto nos permite detectar patrones, outliers, ruido o posibles errores de generaci√≥n.\n\nüí° Nota: Cuando los datos son ‚Äúsint√©ticos‚Äù tenemos la ventaja de conocer la distribuci√≥n exacta que deber√≠an seguir.\n\n\n# Gr√°fico simple de los datos vs. la funci√≥n real\nplt.figure(figsize=(8, 5))\n\nplt.scatter(x_train, y_train, label='Datos generados con ruido', alpha=0.5)\nplt.plot(x_train, np.sin(x_train), color='k', linestyle='--',label='Curva seno verdadera')\n\nplt.legend()\nplt.title('Datos generados de onda seno con ruido')\nplt.xlabel('Valores de X')\nplt.ylabel('Valores de Y')\nplt.show()"
  },
  {
    "objectID": "PINN_notebook.html#red-neuronal",
    "href": "PINN_notebook.html#red-neuronal",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "1.2 üï∏Ô∏è Red Neuronal",
    "text": "1.2 üï∏Ô∏è Red Neuronal\nNuestro objetivo ahora es construir una red neuronal capaz de aprender a ajustar los datos sint√©ticos generados previamente. Para ello, implementaremos un Perceptr√≥n Multicapa (MLP, Multilayer Perceptron), que es la forma m√°s b√°sica ‚Äîy a la vez m√°s vers√°til‚Äî de red neuronal.\n\nUn MLP est√° formado por varias capas lineales (fully connected layers), donde cada neurona se conecta con todas las de la capa anterior.\nEntre estas capas se insertan funciones de activaci√≥n que introducen no linealidad, permitiendo que la red aprenda relaciones complejas entre entrada y salida.\n\nEn t√©rminos generales, nuestro modelo puede entenderse como una funci√≥n, \\(\\hat{y}\\), parametrizada por los pesos(weights) y sesgos(biases) de la red \\((w_{ij}, b_i)\\), que agrupamos bajo el s√≠mbolo \\(\\theta\\). As√≠, la red \\(\\hat{y}_\\theta\\) representa una funci√≥n que depende de estos par√°metros, toma como entrada los valores \\(x_i\\), y produce como salida las predicciones correspondientes.\nArquitectura propuesta\n\nCapa 1: Lineal, transforma las entradas en una representaci√≥n de dimensi√≥n intermedia.\nFunci√≥n de activaci√≥n: puede ser ReLU (m√°s simple y r√°pida) o Tanh (m√°s suave y √∫til para funciones continuas).\nCapa 2: Lineal, genera la salida final del modelo.\n\nAyuda:\n    nn.Linear(input,output)\n    nn.Conv2d(input,output)\n    nn.functional.tanh\n    nn.function.relu\n    nn.function.softmax\n\nclass MLP(nn.Module):\n    def __init__(self):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(1, 10)          # Fully connected layer: 1 input feature, 10 hidden units\n        self.activation = nn.functional.tanh # Funci√≥n de activaci√≥n\n        self.fc2 = nn.Linear(10, 1)          # Fully connected layer: 10 hidden units, 1 output\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.activation(x)\n        x = self.fc2(x)\n        return x\n\nüß† ¬øC√≥mo entrenamos nuestro modelo?\n‚ÄúAprender‚Äù significa ajustar los par√°metros internos de la red ‚Äîdenotados por \\(\\theta\\)‚Äî para que las predicciones \\(\\hat{y}_i\\) se acerquen lo m√°s posible a los valores reales \\(y_i\\). Este proceso se basa en dos componentes esenciales:\n\nMinimizaci√≥n de una funci√≥n de costo (Loss function):\nPara medir qu√© tan bien est√° funcionando el modelo, usamos una funci√≥n de costo que cuantifica el error entre las predicciones y los datos reales. Una de las m√°s comunes es el Error Cuadr√°tico Medio (MSE):\n\\[\n\\mathcal{L} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i - \\hat{y}_i \\right)^2\n\\] donde \\(y_i\\) es el valor real y \\(\\hat{y}_i\\) es la predicci√≥n del modelo para la entrada \\(x_i\\). &gt; Notenemos que necesitamos 3 argumentos \\(\\{x_i,\\hat{y}(x_i),y(x_i)\\}\\) para evaluar esta funci√≥n!\nActualizaci√≥n por descenso del gradiente:\nPara encontrar los valores √≥ptimos de los par√°metros del modelo, \\(\\theta\\), que minimizan la funci√≥n de costo, \\(\\mathcal{L}\\), se utiliza el m√©todo de descenso del gradient (gradient descent). La idea central es mover los par√°metros en la direcci√≥n opuesta al gradiente de la p√©rdida ‚Äîes decir, en la direcci√≥n que m√°s reduce el error:\n\\[\n\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta \\mathcal{L}\n\\]\ndonde:\n\n\\(\\eta\\) es la tasa de aprendizaje (learning rate), que controla qu√© tan grande es cada paso de actualizaci√≥n.\n\\(\\nabla_\\theta \\mathcal{L}\\) es el gradiente de la p√©rdida respecto a los par√°metros del modelo.\n\nEste gradiente indica la direcci√≥n de mayor aumento de la p√©rdida; por eso se resta en la actualizaci√≥n.\nEn la pr√°ctica, los gradientes se calculan mediante diferenciaci√≥n autom√°tica (automatic differentiation) en librer√≠as como PyTorch o TensorFlow.\n\n\nExisten distintos optimizadores que implementan variantes del descenso del gradiente:\n\nSGD (Stochastic Gradient Descent): usa un subconjunto aleatorio de datos en cada iteraci√≥n.\nRMSProp: ajusta din√°micamente el tama√±o de paso para cada par√°metro seg√∫n la magnitud reciente de sus gradientes.\nAdam: combina las ideas de momentum y escalamiento adaptativo de tasa de aprendizaje, siendo hoy el m√°s popular por su estabilidad y rapidez de convergencia.\n\n\nEste ciclo ‚Äîcalcular la p√©rdida ‚Üí obtener los gradientes ‚Üí actualizar par√°metros‚Äî se repite iterativamente hasta que:\n\nla p√©rdida sea lo suficientemente baja,\nel modelo converja, o\nse alcance el n√∫mero m√°ximo de iteraciones.\n\n\nüí° En t√©rminos simples: el modelo aprende a ajustar \\(\\theta\\), repitiendo peque√±os pasos en la direcci√≥n ‚Äúcorrecta‚Äù, hasta que \\(\\hat{y}_\\theta\\) se ajusta a los datos.\n\n\n# Ahora definimos en Pytorch nuestro c√≥digo para entrenar la red:\ndef train_epoch(inputs, model, targets, optimizer, criterion):\n    model.train()\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\n# Ademas agregamos una peque√±a funci√≥n que nos ayuda a evaluar el model\ndef evaluate(model, x_test):\n    model.eval()\n    with torch.no_grad():\n        y_pred = model(x_test.view(-1, 1)).cpu().numpy()\n    return y_pred\n\n\n# Iniciamos las instancias correspondientes\nmodelo       = MLP()\ncriterio     = nn.MSELoss()\noptimizador  = optim.Adam(modelo.parameters(), lr=1e-2)\n\n#numero de parametros de la red\nnumero_parametros = sum(p.numel() for p in modelo.parameters())\nprint(f\"Number of parameters: {numero_parametros}\")\n\nNumber of parameters: 31\n\n\n\n# Y ahora definimos el loop 'iterativo' de entrenamiento\nnum_epocas = 1000\nfor epoca in range(num_epocas):\n    # Convertimos los datos a Tensores de pytorch\n    x_i  = torch.tensor(x_train, dtype=torch.float32, requires_grad=True).view(-1, 1) #inputs\n    y = torch.tensor(y_train, dtype=torch.float32).view(-1, 1) #targets\n\n    # Entrenamos\n    loss = train_epoch(x_i, modelo, y, optimizador, criterio)\n\n    if (epoca+1) % 100 == 0:\n        print(f'Epoch [{epoca+1}/{num_epocas}], Loss: {loss:.4f}')\n\nEpoch [100/1000], Loss: 0.0941\nEpoch [200/1000], Loss: 0.0522\nEpoch [300/1000], Loss: 0.0293\nEpoch [400/1000], Loss: 0.0164\nEpoch [500/1000], Loss: 0.0117\nEpoch [600/1000], Loss: 0.0107\nEpoch [700/1000], Loss: 0.0105\nEpoch [800/1000], Loss: 0.0104\nEpoch [900/1000], Loss: 0.0104\nEpoch [1000/1000], Loss: 0.0103\n\n\nYa tenemos nuestro modelo entrenado! Pero‚Ä¶ ¬ørealmente aprendi√≥ algo √∫til?\nPara responderlo, haremos una inspecci√≥n visual de las predicciones \\(\\hat{y}_i\\) generadas por la red.\nüìà Una visualizaci√≥n t√≠pica incluye:\n\nDatos de entrenamiento: los puntos originales \\((x_i, y_i)\\), que representan nuestras observaciones.\nPredicci√≥n del modelo: la funci√≥n \\(\\hat{y}(x_{\\text{new}})\\) evaluada en un conjunto de puntos nuevos y m√°s densos, para ver la forma continua que aprendi√≥.\nSoluci√≥n real (si la conocemos): \\(y(x_{\\text{new}})\\) evaluada en los mismos puntos del paso anterior, para comparar con la salida de la red.\n\n\nx_test = torch.linspace(0, 2*np.pi, 100) # x_nuevos\ny_pred = evaluate(modelo, x_test) # Nuestro modelo evaluado en los nuevos puntos x\n\nx_test = x_test.cpu().numpy()\ny_test = np.sin(x_test) # Funcion verdadera evaluada en los nuevos puntos x_new\n\nplt.figure(figsize=(10, 6))\nplt.scatter(x_train, y_train, label='Datos de entrenamiento',alpha=0.5)\nplt.plot(x_test, y_pred, label='Curva aprendida', color='red')\nplt.plot(x_test, y_test, color='k', linestyle='--',label='Curva seno verdadera')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nüîç ¬øQu√© podemos observar de este gr√°fico?\n\nSi el modelo captura correctamente la forma general de la funci√≥n (por ejemplo, una senoide).\nSi existen zonas sistem√°ticamente mal ajustadas.\nSi la predicci√≥n es suave, ruidosa o err√°tica.\n\n\nExtra para pensar:\n- ¬øQu√© sucede si incrementamos \\(\\sigma\\) en nuestro generador de datos?\n- ¬øC√≥mo se comporta nuestro modelo para valores m√°s altos o m√°s bajos de \\(\\sigma\\)?\n\nOtro tipo de visualizaci√≥n implica gr√°ficar la curva de la funci√≥n de coste versus el n√∫mero de √©pocas.\nPara ello, modifiqu√© la rutina de entrenamiento para que guarde el valor de la p√©rdida en cada √©poca y luego grafique loss vs epochs.\n\n# num_epochs = 1000\n# for epoch in range(num_epochs):\n#     # Convertimos los datos a Tensores de pytorch\n#     inputs  = torch.tensor(x_train, dtype=torch.float32, requires_grad=True).view(-1, 1) #esto cambien nuestros datos a un tensor de dim (Npuntos,1)\n#     targets = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n\n#     # Entrenamos\n#     loss = train_epoch(inputs, modelo,targets, optimizador, function_coste)\n\n#     if (epoch+1) % 100 == 0:\n#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}')\n\n\n# plt.plot(lista_epocas, lista_costos, lw=2, label = 'Loss entrenamiento')\n# plt.xlabel('Epocas')\n# plt.ylabel('MSE_loss')\n# plt.legend()\n# plt.show()\n\nüîç ¬øQu√© podemos observar de este gr√°fico? - Verificar si el modelo est√° convergiendo. - Detectar oscilaciones o problemas con la tasa de aprendizaje (learning rate, \\(\\eta\\)). - Identificar ‚Äúoverfitting‚Äù si la p√©rdida se estabiliza pero el modelo no mejora"
  },
  {
    "objectID": "PINN_notebook.html#autograd",
    "href": "PINN_notebook.html#autograd",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "1.3 ‚öôÔ∏è Autograd",
    "text": "1.3 ‚öôÔ∏è Autograd\nAhora que ya tenemos nuestro modelo entrenado, podemos hacer algo muy √∫til: calcular derivadas de la salida de la red con respecto a sus entradas.\nEsto es posible gracias a una herramienta fundamental en PyTorch llamada autograd.\nEn otras palabras, podemos evaluar: \\[\\left.\\dfrac{d}{dx}\\hat{y}(x)\\right|_{x_i}\\] de forma autom√°tica, sin necesidad de derivar la red ‚Äúa mano‚Äù.\n\n# Crear un conjunto de inputs con gradientes habilitados\nx_test = torch.linspace(0, 2 * np.pi, 100).view(-1, 1).requires_grad_(True)\n\n# Obtener las predicciones del modelo\npredicciones = modelo(x_test)\n\n# Calcular la derivada de las predicciones respecto a los inputs\ndy_dx = torch.autograd.grad(\n    outputs=predicciones,\n    inputs=x_test,\n    grad_outputs=torch.ones_like(predicciones),\n    create_graph=True,\n    retain_graph=True\n)[0]\n\nVeamos que tan buena es nuestra derivada\n\nplt.figure(figsize=(10, 6))\n\n# Asegurarse de que x y dy_dx est√©n en formato NumPy para usar en matplotlib.plt\nx = x_test.detach().cpu().numpy()\ndy_dx_np = dy_dx.detach().cpu().numpy()\n\n# Graficar derivada real y derivada aprendida\nplt.plot(x, np.cos(x), label='Derivada real (cos(x))', linestyle='--', color='blue', alpha=0.7)\nplt.plot(x, dy_dx_np, label='Derivada autograd del modelo', color='red')\n\n# Est√©tica del gr√°fico\nplt.title('Comparaci√≥n entre derivada real y derivada aprendida')\nplt.xlabel('x')\nplt.ylabel('dy/dx')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nEjercicios extra:\n\nExperimenta con el modelo para explorar c√≥mo responde a distintos escenarios:\n\nPara una funci√≥n rapidamente oscilante \\[\\sin(\\frac{2n\\pi x}{L})\\] con \\(L=1\\) y diferentes valores de \\(n=5,20,50\\).\nQu√© sucede con el modelo?\nQu√© rol juega la capacidad del modelo (n√∫mero de neuronas, activaciones, n√∫mero de capas)\nC√≥mo afecta el tama√±o del dataset y la densidad de puntos?\n\n¬øC√≥mo se podr√≠a calcular la segunda derivada de esta funci√≥n utilizando autograd en PyTorch?\n\n\\[ \\dfrac{d}{dx} \\left(\\dfrac{d}{dx}\\hat{y}(x)\\right)\\]\n\n\nd2y_dx2 = torch.autograd.grad(\n    outputs=dy_dx,\n    inputs=x_test,\n    grad_outputs=torch.ones_like(dy_dx),\n    create_graph=True,\n    retain_graph=True\n)[0]\n\n\nplt.figure(figsize=(10, 6))\n\n# Asegurarse de que x y dy_dx est√©n en formato NumPy\n\nd2y_dx2_np = d2y_dx2.detach().cpu().numpy()\n\n# Graficar derivada real y derivada aprendida\nplt.plot(x, -np.sin(x), label='Segunda Derivada (-sin(x))', linestyle='--', color='blue', alpha=0.7)\nplt.plot(x, d2y_dx2_np, label='Segunda Derivada autograd del modelo', color='red')\n\n# Est√©tica del gr√°fico\nplt.title('Comparaci√≥n entre derivada real y autograd')\nplt.xlabel('x')\nplt.ylabel('d2y/dx2')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "",
    "text": "Juan Calles - juan.calles@uv.cl\n\n\nEscuela de F√≠sica Te√≥rica de Valpara√≠so\n\n\n3 - 4 - 5 de Diciembre de 2025\n\n\nFacultad de Ciencias y Edificio CIAE\n\n\nUniversidad de Valpara√≠so"
  },
  {
    "objectID": "intro.html#c√≥mo-funcionan-las-pinns",
    "href": "intro.html#c√≥mo-funcionan-las-pinns",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "3.1 C√≥mo Funcionan las PINNs",
    "text": "3.1 C√≥mo Funcionan las PINNs\nEn lugar de discretizar el espacio con una malla, una PINN propone que la soluci√≥n f√≠sica sea una funci√≥n continua aproximada por una red neuronal, \\(u_{\\theta}(\\mathbf{x}, t)\\), que aproxima la soluci√≥n de un sistema f√≠sico descrito por una ecuaci√≥n diferencial. Su funcionamiento es una transformaci√≥n de coordenadas: la red recibe una posici√≥n y un tiempo \\((\\mathbf{x}, t)\\) y devuelve directamente el valor de la soluci√≥n en ese punto. La red no almacena la soluci√≥n, sino que la parametriza. Esto genera un mapeo continuo y diferenciable en todo el dominio, eliminando la dependencia de una malla fija.\n\n\n\n\nUna ventaja t√©cnica relevante proviene del uso de automatic differentiation, que permite evaluar derivadas de cualquier orden de \\(u_\\theta\\) de manera exacta dentro del grafo computacional. La Figura ilustra un multi-layer perceptron, en l√≠nea discontinua, del cual podemos obtener gradientes ``gratis‚Äô‚Äô durante el proceso de entrenamiento. Esto evita introducir esquemas de discretizaci√≥n para las derivadas y facilita incorporar directamente los operadores diferenciales que definen el problema f√≠sico.\n\nLo que distingue a una PINN no es la arquitectura de la red, sino c√≥mo se ‚Äúentrena‚Äù. En el aprendizaje autom√°tico tradicional, la red intenta memorizar y generalizar datos, minimizando el error entre predicci√≥n y los dato reales. En una PINN, cambiamos las reglas: le exigimos que ajuste los datos, pero penalizamos cualquier soluci√≥n que viole las leyes de la f√≠sica. B√°sicamente, introducimos explicitamente la Ecuaci√≥n Diferencial dentro de la funci√≥n de costo. Esto obliga a la red a encontrar una soluci√≥n que no solo pase por los datos, sino que obedezca la din√°mica del sistema. Esta informaci√≥n ‚Äúadicional‚Äù puede introducirse a manera de ligaduras, leyes de conservaci√≥n o ecuaciones de movimiento, entre otras formulaciones equivalentes.\nSin p√©rdida de generalidad, consideremos un sistema descrito por el operador diferenccial no-lineal \\(\\mathcal{N}\\) \\[ \\mathcal{N}[u(\\mathbf{x}, t)] = f(\\mathbf{x}, t), \\qquad \\text{donde} \\quad \\mathbf{x} \\in \\Omega \\;; \\quad t \\in [0, T] \\,,\\]\ndefinido en un dominio \\(\\Omega\\) y con condiciones de contorno e iniciales dadas por\n\\[ \\rm{I.C:}\\; u(\\mathbf{x}, 0) = u_0(\\mathbf{x}), \\quad \\mathbf{x} \\in \\Omega \\,.\\] \\[ \\rm{B.C:}\\;\\mathcal{B}[u(\\mathbf{x}, t)] = g(\\mathbf{x}, t), \\quad \\mathbf{x} \\in \\partial\\Omega \\,.\\]\nLa innovaci√≥n crucial de las PINNs consiste en definir una funci√≥n de p√©rdida, \\(\\mathcal{L}\\), que no busca √∫nicamente ajustar datos, sino minimizar simult√°neamente tres t√©rminos:\n\nError de Datos (\\(\\mathcal{L}_{data}\\)): Cuantifica la discrepancia con las observaciones reales o simuladas (si existen). Para \\(N_d\\) puntos de observaci√≥n: \\[\\mathcal{L}_{data} = \\frac{1}{N_d} \\sum_{i=1}^{N_d} |u_{\\theta}(\\mathbf{x}_i, t_i) - y_i|^2\\,.\\]\nError F√≠sico o Residuo (\\(\\mathcal{L}_{PDE}\\)): Este t√©rmino act√∫a como una penalizaci√≥n para restringir el espacio de las soluciones f√≠sicamente aceptables. Definimos el residuo \\(R_\\theta\\) como: \\[R_\\theta(\\mathbf{x}, t) \\equiv \\mathcal{N}[u_\\theta] - f,.\\] Evaluamos este residuo en una nube de \\(N_f\\) puntos de colocaci√≥n \\((\\mathbf{x}_j, t_j)\\) distribuidos en el dominio y construyamos la correspondiente funci√≥n de costo como un error cuadr√°tico medio: \\[\\mathcal{L}_{PDE} = \\frac{1}{N_f} \\sum_{j=1}^{N_f} |R_\\theta(\\mathbf{x}_j, t_j)|^2,.\\] Este procedimiento permite verificar el cumplimiento aproximado de la ecuaci√≥n sin necesidad de discretizar derivadas.\nError en las condiciones de contorno e inicial (\\(\\mathcal{L}_{BC}, \\mathcal{L}_{IC}\\)): Penalizan las desviaciones en los bordes espaciales y el tiempo inicial: \\[\\mathcal{L}_{\\rm{B.C.}} , \\quad \\mathbf{x} \\in \\partial\\Omega,.\\] \\[\\mathcal{L}_{\\rm{I.C.}}, \\quad  t=0 ,.\\] La forma espec√≠fica de estos t√©rminos depende de las condiciones particulares del problema.\n\nLa funci√≥n de costo total combina estos t√©rminos mediante pesos que regulan su contribuci√≥n relativa:\n\\[ \\mathcal{L}_{total} = \\rm{w}_d\\mathcal{L}_{data} + \\rm{w}_p\\mathcal{L}_{PDE} + \\rm{w}_b(\\mathcal{L}_{\\rm{B.C.}}+\\mathcal{L}_{\\rm{I.C.}})\\,,\\]\nsiendo los pesos, \\((\\rm{w}_d, \\rm{w}_p, \\rm{w}_b)\\), hiperpar√°metros definidos seg√∫n las caracter√≠sticas del problema.\nEl entrenamiento utiliza algoritmos de gradiente (Adam o L-BFGS) para encontrar los par√°metros \\(\\theta\\) que minimicen \\(\\mathcal{L}_{total}\\), equilibrando la fidelidad a los datos con la coherencia f√≠sica del sistema."
  },
  {
    "objectID": "intro.html#flujo-de-entrenamiento-de-una-pinn",
    "href": "intro.html#flujo-de-entrenamiento-de-una-pinn",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "3.2 Flujo de Entrenamiento de una PINN",
    "text": "3.2 Flujo de Entrenamiento de una PINN\nEl proceso de entrenamiento de una PINN puede visualizarse mediante el diagrama (Imagen generada por Nano Banana Pro)\n\n\n\nEl proceso puede describirse en cinco pasos esenciales:\n\nDefinir el problema f√≠sico. Seleccionar la PDE y las condiciones iniciales/de contorno que se desean modelar.\nIdentificar datos disponibles. Incorporar mediciones observacionales y cualquier informaci√≥n parcial del sistema.\nDise√±ar la arquitectura. Elegir una red adecuada (MLP, ResNet, CNN, etc.).\nConstruir la funci√≥n de p√©rdida. Combinar error de datos y residuo f√≠sico obtenido por diferenciaci√≥n autom√°tica.\nOptimizar la red. Entrenar los par√°metros mediante m√©todos como Adam o L-BFGS hasta obtener una soluci√≥n que satisfaga simult√°neamente datos y f√≠sica."
  },
  {
    "objectID": "intro.html#qu√©-otras-cosas-podemos-hacer",
    "href": "intro.html#qu√©-otras-cosas-podemos-hacer",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "4.1 ¬øQu√© otras cosas podemos hacer?",
    "text": "4.1 ¬øQu√© otras cosas podemos hacer?\n\nPINNs Bayesianas B-PINNs: Las B-PINNs tratan los pesos de la red neuronal como distribuciones de probabilidad en lugar de valores fijos. Esto permite que la red produzca tanto una predicci√≥n como una estimaci√≥n de incertidumbre (intervalos de confianza), lo cual es crucial para la comparaci√≥n experimental.\nPINNs Variacionales V-PINNs: En lugar de minimizar el residuo de la EDP (forma fuerte), las V-PINNs utilizan la forma d√©bil de la EDP (similar al FEM), integrando las ecuaciones contra funciones de prueba. Esto las hace m√°s robustas frente a datos ruidosos y m√°s capaces de manejar soluciones de baja regularidad.\nSymbolic PINN PISN:\n\n‚Ä¶"
  },
  {
    "objectID": "colab.html",
    "href": "colab.html",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "",
    "text": "Juan Calles - juan.calles@uv.cl\n\n\nEscuela de F√≠sica Te√≥rica de Valpara√≠so\n\n\n3 - 4 - 5 de Diciembre de 2025\n\n\nFacultad de Ciencias y Edificio CIAE\n\n\nUniversidad de Valpara√≠so"
  },
  {
    "objectID": "colab.html#consideraciones-antes-de-empezar",
    "href": "colab.html#consideraciones-antes-de-empezar",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "1.1 Consideraciones antes de empezar:",
    "text": "1.1 Consideraciones antes de empezar:\n\nEs ideal para aprender y experimentar.\nEl tiempo de ejecuci√≥n es limitado, especialmente en el caso de GPU.\nPuede desconectarse autom√°ticamente si est√°s inactivo.\nSi utilizas demasiada memoria (RAM), el notebook puede reiniciarse y perder√°s todo lo que no est√© guardado.\nLas sesiones en Google Colab no son permanentes y tampoco se guardan*.\nSi dejas de usar el notebook por un tiempo o ejecutas procesos muy largos*, Google puede cerrarlo autom√°ticamente.\n\n\nPuedes usar una GPU con TensorFlow o PyTorch, pero el acceso no siempre est√° garantizado. Para comprobar si tu notebook tiene acceso a la GPU, ejecuta el siguiente comando en una celda:\n\n    !nvidia-smi\nSi una GPU est√° habilitada, retornara informaci√≥n sobre la tarjeta gr√°fica"
  },
  {
    "objectID": "colab.html#primeros-pasos-en-google-colab",
    "href": "colab.html#primeros-pasos-en-google-colab",
    "title": "\nPhysics-Informed Neural Networks (PINNs)\n",
    "section": "1.2 Primeros pasos en Google Colab",
    "text": "1.2 Primeros pasos en Google Colab\nPuedes comenzar accediendo al enlace: https://colab.google/\nAl hacerlo, ver√°s una interfaz como la siguiente:\n\n\n\nHaz clic en ‚ÄúNew notebook‚Äù:\n\n\n\nLuego, para revisar las caracter√≠sticas de la ‚Äúm√°quina‚Äù, haz clic en el bot√≥n ‚ÄúConnect‚Äù o en el icono de CPU/RAM:\n\n\n\nPara cambiar de ‚Äúm√°quina‚Äù, selecciona ‚ÄúConnect to a hosted runtime‚Äù:\n\n\n\nAqu√≠ podr√°s especificar el hardware de tu entorno. Por ejemplo, puedes elegir ‚ÄúT4 GPU‚Äù. Una vez activado, deber√≠as ver este recurso disponible:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PINNs - Escuela de F√≠sica Te√≥rica de Valpara√≠so 2025",
    "section": "",
    "text": "Juan Calles - juan.calles@uv.cl\n\n\nEscuela de F√≠sica Te√≥rica de Valpara√≠so\n\n\n3 - 4 - 5 de Diciembre de 2025\n\n\nFacultad de Ciencias y Edificio CIAE\n\n\nUniversidad de Valpara√≠so"
  },
  {
    "objectID": "index.html#contenido",
    "href": "index.html#contenido",
    "title": "PINNs - Escuela de F√≠sica Te√≥rica de Valpara√≠so 2025",
    "section": "1.1 Contenido",
    "text": "1.1 Contenido\n\nIntroducci√≥n a PINNs\nColab\nHands-on session"
  },
  {
    "objectID": "index.html#objetivo",
    "href": "index.html#objetivo",
    "title": "PINNs - Escuela de F√≠sica Te√≥rica de Valpara√≠so 2025",
    "section": "1.2 Objetivo",
    "text": "1.2 Objetivo\nAplicar m√©todos num√©ricos modernos de aprendizaje autom√°tico para resolver problemas f√≠sicos modelados mediante ecuaciones diferenciales parciales (EDPs)."
  },
  {
    "objectID": "index.html#c√≥mo-usar-este-sitio",
    "href": "index.html#c√≥mo-usar-este-sitio",
    "title": "PINNs - Escuela de F√≠sica Te√≥rica de Valpara√≠so 2025",
    "section": "1.3 C√≥mo usar este sitio",
    "text": "1.3 C√≥mo usar este sitio\nPuedes navegar por las secciones desde la barra superior o usando los enlaces anteriores. Cada notebook est√° dise√±ado para ser autoexplicativo y ejecutable."
  },
  {
    "objectID": "PINN_escuela_2025.html",
    "href": "PINN_escuela_2025.html",
    "title": "PINN_escuela_2025",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "PINN_escuela_2025.html#quarto",
    "href": "PINN_escuela_2025.html#quarto",
    "title": "PINN_escuela_2025",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  }
]